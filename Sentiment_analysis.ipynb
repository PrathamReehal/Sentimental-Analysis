{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1743a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Label  \\\n",
      "0         1   \n",
      "1         1   \n",
      "2         1   \n",
      "3         1   \n",
      "4         1   \n",
      "...     ...   \n",
      "6913      0   \n",
      "6914      0   \n",
      "6915      0   \n",
      "6916      0   \n",
      "6917      0   \n",
      "\n",
      "                                                                                                                              Text  \n",
      "0                                                                                          The Da Vinci Code book is just awesome.  \n",
      "1     this was the first clive cussler i've ever read, but even books like Relic, and Da Vinci code were more plausible than this.  \n",
      "2                                                                                                 i liked the Da Vinci Code a lot.  \n",
      "3                                                                                                 i liked the Da Vinci Code a lot.  \n",
      "4                                                         I liked the Da Vinci Code but it ultimatly didn't seem to hold it's own.  \n",
      "...                                                                                                                            ...  \n",
      "6913                                                                                                Brokeback Mountain was boring.  \n",
      "6914                                                                                  So Brokeback Mountain was really depressing.  \n",
      "6915              As I sit here, watching the MTV Movie Awards, I am reminded of how much I despised the movie Brokeback Mountain.  \n",
      "6916                                                                               Ok brokeback mountain is such a horrible movie.  \n",
      "6917                                                                              Oh, and Brokeback Mountain was a terrible movie.  \n",
      "\n",
      "[6918 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the .txt file where each line is a separate entry\n",
    "df = pd.read_csv('training.txt', delimiter='\\t', header=None, names=['Label', 'Text'])\n",
    "\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7ffd806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 800)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e627bd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c24ada62",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer()\n",
    "#now create dictionary\n",
    "feature_ext=count_vectorizer.fit(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27231095",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=feature_ext.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "565ebee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2132"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4b518a00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['barnyard',\n",
       " '7th',\n",
       " '007',\n",
       " 'suppose',\n",
       " 'thank',\n",
       " 'jesus',\n",
       " 'empty',\n",
       " 'done',\n",
       " 'donkey',\n",
       " 'finshed']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(list(features),10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d28cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating count vectors from documents in dataset\n",
    "train_df_features=count_vectorizer.transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10a4ed31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6918x2132 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 65398 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd845cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dataframe of all count vectors and assigning features or all unique words as columns header\n",
    "train_ds=pd.DataFrame(train_df_features.todense())\n",
    "train_ds.columns=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a9939063",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The Da Vinci Code book is just awesome.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                     Text\n",
       "0      1  The Da Vinci Code book is just awesome."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2cd54ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>away</th>\n",
       "      <th>awesome</th>\n",
       "      <th>awesomely</th>\n",
       "      <th>awesomeness</th>\n",
       "      <th>awesomest</th>\n",
       "      <th>awful</th>\n",
       "      <th>awkward</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   away  awesome  awesomely  awesomeness  awesomest  awful  awkward\n",
       "0     0        1          0            0          0      0        0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.iloc[0:1,150:157]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dfe1cbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing low frequency words or features\n",
    "import numpy as np\n",
    "features_count=np.sum(train_df_features.toarray(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cef82cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count=pd.DataFrame(dict(features=features,counts=features_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d93b6715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1228"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_count[features_count.counts==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43bbc5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer()\n",
    "#now create dictionary\n",
    "feature_ext=count_vectorizer.fit(df['Text'])\n",
    "features=feature_ext.get_feature_names_out()\n",
    "train_df_features=count_vectorizer.transform(df['Text'])\n",
    "train_ds=pd.DataFrame(train_df_features.todense())\n",
    "train_ds.columns=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "152f371d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>the</td>\n",
       "      <td>3306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>and</td>\n",
       "      <td>2154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>harry</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1466</th>\n",
       "      <td>potter</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>355</th>\n",
       "      <td>code</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>vinci</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>da</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>mountain</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>love</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>is</td>\n",
       "      <td>1520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2029</th>\n",
       "      <td>was</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>awesome</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>impossible</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        features  counts\n",
       "1864         the    3306\n",
       "93           and    2154\n",
       "864        harry    2093\n",
       "1466      potter    2093\n",
       "355         code    2002\n",
       "2009       vinci    2001\n",
       "442           da    2001\n",
       "1272    mountain    2000\n",
       "259    brokeback    2000\n",
       "1171        love    1624\n",
       "1018          is    1520\n",
       "2029         was    1176\n",
       "151      awesome    1127\n",
       "1252     mission    1094\n",
       "977   impossible    1093"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "features_count=np.sum(train_df_features.toarray(),axis=0)\n",
    "features_count=pd.DataFrame(dict(features=features,counts=features_count))\n",
    "features_count.sort_values('counts',ascending = False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dccd4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing stopwords\n",
    "from sklearn.feature_extraction import text \n",
    "my_stop_words=text.ENGLISH_STOP_WORDS\n",
    "my_stop_words = list(text.ENGLISH_STOP_WORDS.union(['harry', 'potter',\n",
    "'code', 'vinci', 'da','harry', 'mountain', 'movie', 'movies']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2d4a1582",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer(stop_words=my_stop_words,max_features=1000)\n",
    "#now create dictionary\n",
    "feature_ext=count_vectorizer.fit(df['Text'])\n",
    "features=feature_ext.get_feature_names_out()\n",
    "train_df_features=count_vectorizer.transform(df['Text'])\n",
    "train_ds=pd.DataFrame(train_df_features.todense())\n",
    "train_ds.columns=features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb5314b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>love</td>\n",
       "      <td>1624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>awesome</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>impossible</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>like</td>\n",
       "      <td>974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>sucks</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>sucked</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>hate</td>\n",
       "      <td>578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>really</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>stupid</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>just</td>\n",
       "      <td>287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>know</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>suck</td>\n",
       "      <td>276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>loved</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       features  counts\n",
       "73    brokeback    2000\n",
       "408        love    1624\n",
       "39      awesome    1127\n",
       "436     mission    1094\n",
       "341  impossible    1093\n",
       "390        like     974\n",
       "745       sucks     602\n",
       "743      sucked     600\n",
       "297        hate     578\n",
       "652      really     374\n",
       "741      stupid     365\n",
       "362        just     287\n",
       "374        know     276\n",
       "742        suck     276\n",
       "409       loved     256"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts=np.sum(train_df_features.toarray(),axis=0)\n",
    "feature_counts=pd.DataFrame(dict(features=features,counts=feature_counts))\n",
    "feature_counts.sort_values('counts',ascending = False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "de5d57c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stemming and stopword removal\n",
    "from nltk.stem.snowball import PorterStemmer\n",
    "stemmer=PorterStemmer()\n",
    "analyzer=CountVectorizer().build_analyzer()\n",
    "def stemmed_word(doc):\n",
    "    #stemming word\n",
    "    stemmed_words=[stemmer.stem(w) for w in analyzer(doc)]\n",
    "    # remove stopwords\n",
    "    non_stop=[word for word in stemmed_words if word not in my_stop_words]\n",
    "    return non_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7c4995ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer=CountVectorizer(analyzer=stemmed_word,max_features=1000)\n",
    "#now create dictionary\n",
    "feature_ext=count_vectorizer.fit(df['Text'])\n",
    "features=feature_ext.get_feature_names_out()\n",
    "train_df_features=count_vectorizer.transform(df['Text'])\n",
    "train_ds=pd.DataFrame(train_df_features.todense())\n",
    "train_ds.columns=features\n",
    "train_ds['sentiment'] = df['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d78e8eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>harri</td>\n",
       "      <td>2093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>brokeback</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>love</td>\n",
       "      <td>1883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>suck</td>\n",
       "      <td>1484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>wa</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>like</td>\n",
       "      <td>1155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>movi</td>\n",
       "      <td>1149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>awesom</td>\n",
       "      <td>1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>mission</td>\n",
       "      <td>1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>imposs</td>\n",
       "      <td>1093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>hate</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>becaus</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>realli</td>\n",
       "      <td>374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>stupid</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>know</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      features  counts\n",
       "303      harri    2093\n",
       "83   brokeback    2000\n",
       "414       love    1883\n",
       "791       suck    1484\n",
       "922         wa    1176\n",
       "400       like    1155\n",
       "447       movi    1149\n",
       "45      awesom    1130\n",
       "441    mission    1094\n",
       "351     imposs    1093\n",
       "305       hate     701\n",
       "56      becaus     608\n",
       "615     realli     374\n",
       "784     stupid     365\n",
       "386       know     360"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_counts=np.sum(train_df_features.toarray(),axis=0)\n",
    "feature_counts=pd.DataFrame(dict(features=features,counts=feature_counts))\n",
    "feature_counts.sort_values('counts',ascending = False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "41984cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(train_df_features, train_ds.sentiment,\n",
    "                                                test_size = 0.3,\n",
    "                                                random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fa4c0ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "nb_clf = BernoulliNB()\n",
    "nb_clf.fit(train_X.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28be0552",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds_predicted = nb_clf.predict(test_X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ce032782",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.98       873\n",
      "           1       0.98      0.99      0.98      1203\n",
      "\n",
      "    accuracy                           0.98      2076\n",
      "   macro avg       0.98      0.98      0.98      2076\n",
      "weighted avg       0.98      0.98      0.98      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(test_y, test_ds_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ef58aac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9802504816955684\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print('accuracy:',accuracy_score(test_ds_predicted,test_y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "68342681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(train_X.toarray(), train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "104c36a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9903660886319846\n"
     ]
    }
   ],
   "source": [
    "test_rf_predicted = rf_classifier.predict(test_X.toarray())\n",
    "print('accuracy:',accuracy_score(test_rf_predicted,test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d914cc4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       873\n",
      "           1       0.99      0.99      0.99      1203\n",
      "\n",
      "    accuracy                           0.99      2076\n",
      "   macro avg       0.99      0.99      0.99      2076\n",
      "weighted avg       0.99      0.99      0.99      2076\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_y, test_rf_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e2db3d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer embedding weight shape (16185, 100) is not compatible with provided weight shape (16184, 100).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 43\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[1;32m     42\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m---> 43\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Embedding(input_dim\u001b[38;5;241m=\u001b[39mvocab_size, output_dim\u001b[38;5;241m=\u001b[39membedding_dim, weights\u001b[38;5;241m=\u001b[39m[word2vec_weights], input_length\u001b[38;5;241m=\u001b[39mmax_length, trainable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[1;32m     44\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m128\u001b[39m, return_sequences\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[1;32m     45\u001b[0m model\u001b[38;5;241m.\u001b[39madd(LSTM(\u001b[38;5;241m64\u001b[39m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/keras/engine/base_layer.py:1827\u001b[0m, in \u001b[0;36mLayer.set_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1825\u001b[0m ref_shape \u001b[38;5;241m=\u001b[39m param\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ref_shape\u001b[38;5;241m.\u001b[39mis_compatible_with(weight_shape):\n\u001b[0;32m-> 1827\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1828\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLayer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m weight shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mref_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1829\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not compatible with provided weight \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1830\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mweight_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1831\u001b[0m     )\n\u001b[1;32m   1832\u001b[0m weight_value_tuples\u001b[38;5;241m.\u001b[39mappend((param, weight))\n\u001b[1;32m   1833\u001b[0m weight_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Layer embedding weight shape (16185, 100) is not compatible with provided weight shape (16184, 100)."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load training and testing data\n",
    "train_df = pd.read_csv('training.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Combine train and test texts for tokenization\n",
    "all_texts = pd.concat([train_df['text'], test_df['text']], axis=0)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_length = max([len(seq) for seq in train_sequences + test_sequences])\n",
    "X_train = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['label'])\n",
    "y_test = label_encoder.transform(test_df['label'])\n",
    "\n",
    "# Train Word2Vec on the combined texts\n",
    "word2vec_model = Word2Vec(sentences=[text.split() for text in all_texts], vector_size=100, window=5, min_count=1, workers=4)\n",
    "word2vec_weights = word2vec_model.wv.vectors\n",
    "embedding_dim = word2vec_weights.shape[1]\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[word2vec_weights], input_length=max_length, trainable=False))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "872ee492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 20:15:03.059136: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:03.060374: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:03.060737: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:15:03.119179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:03.119613: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:03.120053: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:15:03.172029: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-09-04 20:15:03.326800: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:03.327444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:03.327975: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:15:03.398753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:03.399162: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:03.399666: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:15:03.618648: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:03.619220: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:03.619924: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:15:03.681807: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:03.682318: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:03.682802: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - ETA: 0s - loss: 1.5850 - accuracy: 0.3299"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 20:15:24.134669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:24.135235: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:24.135902: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:15:24.213334: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:15:24.213876: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:15:24.214319: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "450/450 [==============================] - 22s 47ms/step - loss: 1.5850 - accuracy: 0.3299 - val_loss: 1.5731 - val_accuracy: 0.3187\n",
      "Epoch 2/5\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.5786 - accuracy: 0.3338 - val_loss: 1.5740 - val_accuracy: 0.3187\n",
      "Epoch 3/5\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.5784 - accuracy: 0.3322 - val_loss: 1.5710 - val_accuracy: 0.3187\n",
      "Epoch 4/5\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.5793 - accuracy: 0.3313 - val_loss: 1.5744 - val_accuracy: 0.3187\n",
      "Epoch 5/5\n",
      "450/450 [==============================] - 21s 47ms/step - loss: 1.5778 - accuracy: 0.3347 - val_loss: 1.5729 - val_accuracy: 0.3187\n",
      " 1/63 [..............................] - ETA: 16s - loss: 1.5538 - accuracy: 0.2500"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 20:16:49.937569: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:16:49.938101: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:16:49.938754: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-09-04 20:16:50.002224: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-09-04 20:16:50.002724: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-09-04 20:16:50.003189: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 14ms/step - loss: 1.5604 - accuracy: 0.3475\n",
      "Test Accuracy: 0.3475\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load training and testing data\n",
    "train_df = pd.read_csv('training.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Combine train and test texts for tokenization\n",
    "all_texts = pd.concat([train_df['text'], test_df['text']], axis=0)\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(all_texts)\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Train Word2Vec on the combined texts\n",
    "word2vec_model = Word2Vec(sentences=[text.split() for text in all_texts], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Prepare the embedding matrix\n",
    "embedding_dim = word2vec_model.vector_size\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_matrix[i] = word2vec_model.wv[word]\n",
    "\n",
    "# Convert text to sequences\n",
    "train_sequences = tokenizer.texts_to_sequences(train_df['text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_df['text'])\n",
    "\n",
    "# Pad sequences to ensure uniform input size\n",
    "max_length = max([len(seq) for seq in train_sequences + test_sequences])\n",
    "X_train = pad_sequences(train_sequences, maxlen=max_length, padding='post')\n",
    "X_test = pad_sequences(test_sequences, maxlen=max_length, padding='post')\n",
    "\n",
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_df['label'])\n",
    "y_test = label_encoder.transform(test_df['label'])\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(word_index) + 1, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfd5e38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
